{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this notebook we make predictions on the severity of a harmful algal bloom based on Landsat and Sentinel satellite imagery\n",
    "\n",
    "Inputs:\n",
    "    Satellite Image (preferably sentinel, but if not available, landsat)\n",
    "    Temperature Data (hrrr)\n",
    "    \n",
    "Outputs:\n",
    "    Severyty of Harmful Algal Bloom on a scale of 1-5 (1 being the least severe, 5 being the most severe)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "DATA_DIR = Path.cwd() / 'data'\n",
    "MODEL_DIR = Path.cwd() / 'models'\n",
    "RESULTS_DIR = Path.cwd() / 'results'\n",
    "IMAGE_DIR = DATA_DIR / 'images'\n",
    "# IMAGE_DIR = DATA_DIR / 'sentinel-images'\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "'''\n",
    "transform_image = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.CenterCrop((480, 480)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "'''\n",
    "\n",
    "transform_image = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff\n",
    "temp_scalar = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"EfficientNetV2 Model\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): Number of classes\n",
    "        dropout (float): Dropout rate\n",
    "    \"\"\"\n",
    "    def __init__(self, metadata_embed = None, dropout=0.2):\n",
    "        super(CNN, self).__init__()\n",
    "        # EfficientNetV2 base\n",
    "        # self.pretrained_cnn = models.efficientnet_v2_s(weights='DEFAULT')\n",
    "        # cnn_out = self.pretrained_cnn.classifier[1].in_features\n",
    "        # self.pretrained_cnn = nn.Sequential(*list(self.pretrained_cnn.children())[:-1])\n",
    "        \n",
    "        # ResNet50 base\n",
    "        self.pretrained_cnn = models.resnet50(weights='DEFAULT')\n",
    "        cnn_out = self.pretrained_cnn.fc.in_features\n",
    "        self.pretrained_cnn = nn.Sequential(*list(self.pretrained_cnn.children())[:-1])\n",
    "        \n",
    "        fc_in = cnn_out\n",
    "        \n",
    "        if metadata_embed is not None:\n",
    "            self.lin = nn.Linear(1, metadata_embed)\n",
    "            fc_in += metadata_embed\n",
    "        \n",
    "        fc_embed = fc_in//2\n",
    "        fc_out = fc_embed//2\n",
    "            \n",
    "        # Add fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(fc_in, fc_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(fc_embed, fc_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        \n",
    "        # Final classifier layer\n",
    "        self.classifier = nn.Linear(fc_out, NUM_CLASSES)\n",
    "        \n",
    "        \n",
    "    def forward(self, img, met=None):\n",
    "        \"\"\"EfficientNetV2 forward pass\n",
    "        \n",
    "        Args:\n",
    "            img (torch.Tensor): Input image\n",
    "            met (torch.Tensor): Input metadata features\n",
    "            \n",
    "        Returns:\n",
    "            preds (torch.Tensor): Predicted labels\n",
    "        \"\"\"\n",
    "        img_features = self.pretrained_cnn(img)                             # (batch_size, cnn_out, 1, 1)\n",
    "        \n",
    "        img_features = img_features.view(img_features.size(0), -1)          # (batch_size, cnn_out)\n",
    "        \n",
    "        \n",
    "        if met is not None:\n",
    "            met_features = self.lin(met.unsqueeze(dim=1))\n",
    "            features = torch.cat((img_features, met_features), dim=1)   # (batch_size, cnn_out+metadata_features)\n",
    "        else:\n",
    "            features = img_features\n",
    "            \n",
    "        \n",
    "        features = self.fc(features)\n",
    "                \n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def RMSELoss(y_features, y_targets):\n",
    "#     \"\"\"RMSE Loss\n",
    "    \n",
    "#     Args:\n",
    "#         y_features (torch.Tensor): Model features\n",
    "#         y_targets (torch.Tensor): Target labels\n",
    "        \n",
    "#     Returns:\n",
    "#         loss (torch.Tensor): Loss value\n",
    "#     \"\"\"\n",
    "#     y_preds = torch.argmax(F.softmax(y_features, dim=1), dim=1)\n",
    "    \n",
    "#     loss = torch.sqrt(F.mse_loss(y_preds, y_targets))\n",
    "    \n",
    "#     return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, df, image_transform=None):\n",
    "        self.df = df\n",
    "        self.uids = self.df['uid'].to_numpy()\n",
    "        # self.temps = self.df['temperature'].to_numpy(dtype=np.float32)\n",
    "        self.targets = self.df['severity'].to_numpy()\n",
    "\n",
    "        self.image_transform = image_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_pth = IMAGE_DIR / f\"{self.uids[index]}.png\"\n",
    "        image = Image.open(image_pth)\n",
    "        \n",
    "        if self.image_transform is not None:\n",
    "            image = self.image_transform(image)\n",
    "                    \n",
    "        return self.uids[index], image, self.targets[index] # returns (uid, image, target/severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(df, transform, batch_size=32, shuffle=True, num_workers=0, pin_memory=True):\n",
    "    \n",
    "    dataset = SatelliteDataset(df, transform)\n",
    "    \n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    \n",
    "    return loader, dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv files\n",
    "metadata = pd.read_csv(DATA_DIR / 'c20p-metadata.csv')\n",
    "metadata.date = pd.to_datetime(metadata.date)\n",
    "\n",
    "train_labels = pd.read_csv(DATA_DIR / 'train_labels.csv')\n",
    "\n",
    "submission_format = pd.read_csv(DATA_DIR / 'submission_format.csv')\n",
    "\n",
    "temperature = pd.read_csv(DATA_DIR / 'temperature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_temp = temperature.copy()\n",
    "scaled_temp.temperature = temp_scalar.fit_transform(scaled_temp.temperature.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_temp = metadata.merge(\n",
    "    scaled_temp,\n",
    "    how=\"inner\",\n",
    "    left_on='uid',\n",
    "    right_on='uid',\n",
    "    validate='1:1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get entire train set from metadata file\n",
    "train_full = train_labels.merge(\n",
    "    metadata,\n",
    "    how='inner',\n",
    "    left_on='uid',\n",
    "    right_on='uid',\n",
    "    validate='1:1',\n",
    ")\n",
    "train_full = train_full[['uid', 'severity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets to better evaluate the model\n",
    "train, validate = train_test_split(train_full, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test set from metadata file\n",
    "test_full = metadata_temp[metadata_temp['split'] == 'test']\n",
    "test = submission_format.merge(\n",
    "    test_full,\n",
    "    how='inner',\n",
    "    left_on='uid',\n",
    "    right_on='uid',\n",
    "    validate='1:1',\n",
    ")\n",
    "test = test[['uid', 'region', 'severity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11207, 2802, 4258)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(validate), len(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-5\n",
    "dropout = 0.3\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "num_epochs = 10\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataloaders\n",
    "train_loader, train_dataset = get_loader(train, transform_image, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader, val_dataset = get_loader(validate, transform_image, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader, test_dataset = get_loader(test, transform_image, batch_size=1, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = CNN(dropout=dropout).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean').to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model_to_save, filename='checkpoint.pt'):\n",
    "    torch.save(model_to_save.state_dict(), MODEL_DIR / filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 1.0623 - Val Loss: 0.9865: 100%|██████████| 273/273 [00:15<00:00, 18.09it/s]\n",
      "Epoch 2/10 - Train Loss: 0.9684 - Val Loss: 1.0514: 100%|██████████| 273/273 [00:13<00:00, 19.65it/s]\n",
      "Epoch 3/10 - Train Loss: 0.9195 - Val Loss: 1.3018: 100%|██████████| 273/273 [00:14<00:00, 18.98it/s]\n",
      "Epoch 4/10 - Train Loss: 0.8870 - Val Loss: 0.9277: 100%|██████████| 273/273 [00:13<00:00, 19.84it/s]\n",
      "Epoch 5/10 - Train Loss: 0.8470 - Val Loss: 0.9401: 100%|██████████| 273/273 [00:13<00:00, 19.76it/s]\n",
      "Epoch 6/10 - Train Loss: 0.7915 - Val Loss: 1.0354: 100%|██████████| 273/273 [00:13<00:00, 19.75it/s]\n",
      "Epoch 7/10 - Train Loss: 0.7289:  14%|█▍        | 155/1090 [00:21<02:09,  7.24it/s]"
     ]
    }
   ],
   "source": [
    "best_loss = None\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ## TRAINING LOOP\n",
    "    train_count = 0\n",
    "    train_loss = 0\n",
    "    avg_train_loss = 0\n",
    "    pbar_train = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "    model.train()\n",
    "    for idx, (uids, imgs, targets) in enumerate(pbar_train):\n",
    "        # Move data to device\n",
    "        imgs = imgs.to(device)\n",
    "        # temperatures = temperatures.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass   \n",
    "        outputs = model(\n",
    "            imgs, \n",
    "            # temperatures,\n",
    "        )\n",
    "        loss = criterion(outputs, targets)\n",
    "        #rmse = RMSELoss(outputs, targets)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_count += 1\n",
    "        train_loss += loss.item()\n",
    "        avg_train_loss = train_loss/train_count\n",
    "        desc = (\n",
    "            f\"Epoch {epoch+1}/{num_epochs}\"\n",
    "            f\" - Train Loss: {avg_train_loss:.4f}\"\n",
    "        )\n",
    "        pbar_train.set_description(desc=desc)\n",
    "    \n",
    "    \n",
    "    ## VALIDATION LOOP   \n",
    "    val_count = 0\n",
    "    val_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    pbar_val = tqdm(val_loader, total=len(val_loader), leave=True)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (uid, imgs, targets) in enumerate(pbar_val):\n",
    "            # Move data to device\n",
    "            imgs = imgs.to(device)\n",
    "            # temperatures = temperatures.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                imgs,\n",
    "                # temperatures,\n",
    "            )\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Update progress bar\n",
    "            val_count += 1\n",
    "            val_loss += loss.item()\n",
    "            avg_val_loss = val_loss/val_count\n",
    "            desc = (\n",
    "                f\"Epoch {epoch+1}/{num_epochs}\"\n",
    "                f\" - Train Loss: {avg_train_loss:.4f}\"\n",
    "                f\" - Val Loss: {avg_val_loss:.4f}\"\n",
    "            )\n",
    "            pbar_val.set_description(desc=desc)\n",
    "            \n",
    "    \n",
    "    ## CHECKPOINTING AND EARLY STOPPING\n",
    "    if best_loss is None:   # i.e. first epoch\n",
    "        best_loss = avg_val_loss\n",
    "        save_checkpoint(model, filename=f'checkpoint.pt')\n",
    "        \n",
    "    elif avg_val_loss > best_loss:  # i.e. loss increased\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print('Validation loss has not decreased. Stopping training.')\n",
    "            break\n",
    "        \n",
    "    else:   # avg_val_loss < best_loss i.e. loss decreased\n",
    "        best_loss = avg_val_loss\n",
    "        save_checkpoint(model, filename=f'checkpoint.pt')\n",
    "        counter = 0\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN().to(device) # metadata_embed=256\n",
    "\n",
    "model_pth = MODEL_DIR / 'checkpoint.pt'\n",
    "model.load_state_dict(torch.load(model_pth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4258/4258 [01:18<00:00, 53.91it/s]\n"
     ]
    }
   ],
   "source": [
    "submission = submission_format.copy()\n",
    "\n",
    "results = {}\n",
    "\n",
    "model.eval()\n",
    "pbar = tqdm(test_loader, total=len(test_loader), leave=True)\n",
    "for idx, (uid, img,  _) in enumerate(pbar):\n",
    "    uid = uid[0]\n",
    "    # temperature = temperature.to(device)\n",
    "    img = img.to(device)\n",
    "    \n",
    "    output = model(\n",
    "        img,\n",
    "        # temperature,\n",
    "    )\n",
    "    \n",
    "    prediction = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
    "    \n",
    "    submission.loc[submission.uid == uid, 'severity'] = prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabn</td>\n",
       "      <td>west</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aair</td>\n",
       "      <td>west</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aajw</td>\n",
       "      <td>northeast</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aalr</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aalw</td>\n",
       "      <td>west</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>zzpn</td>\n",
       "      <td>northeast</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>zzrv</td>\n",
       "      <td>west</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6507</th>\n",
       "      <td>zzsx</td>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>zzvv</td>\n",
       "      <td>west</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>zzzi</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6510 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid     region  severity\n",
       "0     aabn       west         1\n",
       "1     aair       west         1\n",
       "2     aajw  northeast         1\n",
       "3     aalr    midwest         1\n",
       "4     aalw       west         4\n",
       "...    ...        ...       ...\n",
       "6505  zzpn  northeast         1\n",
       "6506  zzrv       west         4\n",
       "6507  zzsx      south         1\n",
       "6508  zzvv       west         4\n",
       "6509  zzzi    midwest         1\n",
       "\n",
       "[6510 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4747\n",
       "2      35\n",
       "3     473\n",
       "4    1255\n",
       "Name: severity, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.severity.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4544\n",
       "2     104\n",
       "3     486\n",
       "4    1376\n",
       "Name: severity, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.severity.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(RESULTS_DIR / '5_notemp-cnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5064345b0d58fd2fcf3dda7597a90bdf293cddcb997317e100b9e3dab1db3ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
