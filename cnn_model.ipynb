{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "DATA_DIR = Path.cwd() / 'data'\n",
    "MODEL_DIR = Path.cwd() / 'models'\n",
    "#IMAGE_DIR = DATA_DIR / 'images'\n",
    "IMAGE_DIR = DATA_DIR / 'sentinel-images'\n",
    "'''\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((480, 480), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "'''\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(256, 256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.uids = self.df['uid'].tolist()\n",
    "        self.targets = self.df['severity'].tolist()\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_pth = IMAGE_DIR / f\"{self.uids[index]}.png\"\n",
    "        image = Image.open(image_pth)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return self.uids[index], image, self.targets[index] # returns uid, image, target/severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(df, transform, batch_size=32, shuffle=True, num_workers=0, pin_memory=True):\n",
    "    \n",
    "    dataset = SatelliteDataset(df, transform)\n",
    "    \n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    \n",
    "    return loader, dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"EfficientNetV2 Model\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): Number of classes\n",
    "        dropout (float): Dropout rate\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, dropout=0.2):\n",
    "        super(CNN, self).__init__()\n",
    "        # EfficientNetV2 base\n",
    "        # self.pretrained_cnn = models.efficientnet_v2_s(weights='DEFAULT')\n",
    "        # in_features = self.pretrained_cnn.classifier[1].in_features\n",
    "        # self.pretrained_cnn = nn.Sequential(*list(self.pretrained_cnn.children())[:-1])\n",
    "        \n",
    "        \n",
    "        # ResNet50 base\n",
    "        self.pretrained_cnn = models.resnet50(weights='DEFAULT')\n",
    "        in_features = self.pretrained_cnn.fc.in_features\n",
    "        self.pretrained_cnn = nn.Sequential(*list(self.pretrained_cnn.children())[:-1])\n",
    "        \n",
    "        \n",
    "        # Add fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features//2, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Final softmax layer\n",
    "        #self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        \"\"\"EfficientNetV2 forward pass\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input image\n",
    "            targets (torch.Tensor): Target labels\n",
    "            \n",
    "        Returns:\n",
    "            preds (torch.Tensor): Predicted labels\n",
    "            loss (torch.Tensor): Loss value\n",
    "        \"\"\"\n",
    "        features = self.pretrained_cnn(x)                 # (batch_size, 1280, 1, 1)\n",
    "        features = features.view(features.size(0), -1)  # (batch_size, 1280)\n",
    "        features = self.fc(features)                    # (batch_size, num_classes)\n",
    "        \n",
    "        #preds = self.softmax(features)                  # (batch_size, num_classes)\n",
    "        #preds = torch.argmax(preds, dim=1)              # (batch_size)\n",
    "        \n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            pass\n",
    "        \n",
    "        return features, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSELoss(y_features, y_targets):\n",
    "    \"\"\"RMSE Loss\n",
    "    \n",
    "    Args:\n",
    "        y_features (torch.Tensor): Model features\n",
    "        y_targets (torch.Tensor): Target labels\n",
    "        \n",
    "    Returns:\n",
    "        loss (torch.Tensor): Loss value\n",
    "    \"\"\"\n",
    "    y_preds = torch.argmax(F.softmax(y_features, dim=1), dim=1)\n",
    "    \n",
    "    loss = torch.sqrt(F.mse_loss(y_preds, y_targets))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv files\n",
    "metadata = pd.read_csv(DATA_DIR / 'sentinel-metadata.csv')\n",
    "metadata.date = pd.to_datetime(metadata.date)\n",
    "\n",
    "train_labels = pd.read_csv(DATA_DIR / 'train_labels.csv')\n",
    "submission_format = pd.read_csv(DATA_DIR / 'submission_format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 5\n",
    "learning_rate = 3e-4\n",
    "dropout = 0.2\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get entire train set from metadata file\n",
    "train_full = train_labels.merge(\n",
    "    metadata,\n",
    "    how='inner',\n",
    "    left_on='uid',\n",
    "    right_on='uid',\n",
    "    validate='1:1',\n",
    ")\n",
    "train_full = train_full[['uid', 'severity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets to better evaluate the model\n",
    "train, validate = train_test_split(train_full, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test set from metadata file\n",
    "test_full = metadata[metadata['split'] == 'test']\n",
    "test = submission_format.merge(\n",
    "    test_full,\n",
    "    how='inner',\n",
    "    left_on='uid',\n",
    "    right_on='uid',\n",
    "    validate='1:1',\n",
    ")\n",
    "test = test[['uid', 'region', 'severity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataloaders\n",
    "train_loader, train_dataset = get_loader(train, transform, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader, test_dataset = get_loader(validate, transform, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = CNN(num_classes, dropout=dropout).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean').to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 0.9831 - Val Loss: 0.9337: 100%|██████████| 226/226 [00:11<00:00, 19.74it/s]\n",
      "Epoch 2/5 - Train Loss: 0.8924 - Val Loss: 0.9417: 100%|██████████| 226/226 [00:11<00:00, 19.74it/s]\n",
      "Epoch 3/5 - Train Loss: 0.8447 - Val Loss: 0.9746: 100%|██████████| 226/226 [00:10<00:00, 20.68it/s]\n",
      "Epoch 4/5 - Train Loss: 0.8046 - Val Loss: 0.9668: 100%|██████████| 226/226 [00:10<00:00, 21.54it/s]\n",
      "Epoch 5/5 - Train Loss: 0.7566:  76%|███████▌  | 689/904 [01:36<00:30,  7.14it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    train_images = 0\n",
    "    train_loss = 0\n",
    "    pbar_train = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "    model.train()\n",
    "    for idx, (uid, imgs, targets) in enumerate(pbar_train):\n",
    "        # Move data to device\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass   \n",
    "        outputs, _ = model(imgs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        #rmse = RMSELoss(outputs, targets)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_images += 1\n",
    "        train_loss += loss.item()\n",
    "        desc = (\n",
    "            f\"Epoch {epoch+1}/{num_epochs}\"\n",
    "            f\" - Train Loss: {train_loss/train_images:.4f}\"\n",
    "        )\n",
    "        pbar_train.set_description(desc=desc)\n",
    "    \n",
    "    # Validation loop    \n",
    "    val_images = 0\n",
    "    val_loss = 0\n",
    "    pbar_val = tqdm(val_loader, total=len(val_loader), leave=True)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (uid, imgs, targets) in enumerate(pbar_val):\n",
    "            # Move data to device\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, _ = model(imgs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Update progress bar\n",
    "            val_images += 1\n",
    "            val_loss += loss.item()\n",
    "            desc = (\n",
    "                f\"Epoch {epoch+1}/{num_epochs}\"\n",
    "                f\" - Train Loss: {train_loss/train_images:.4f}\"\n",
    "                f\" - Val Loss: {val_loss/val_images:.4f}\"\n",
    "            )\n",
    "            pbar_val.set_description(desc=desc)\n",
    "    \n",
    "    log = (\n",
    "        f\"Epoch {epoch+1}/{num_epochs}\"\n",
    "        f\" - Train Loss: {train_loss/train_images:.4f}\"\n",
    "        f\" - Val Loss: {val_loss/val_images:.4f}\"\n",
    "    )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pth = MODEL_DIR / 'model.pt'\n",
    "torch.save(model.state_dict(), model_pth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(num_classes).to(device)\n",
    "model.load_state_dict(torch.load(model_pth))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5064345b0d58fd2fcf3dda7597a90bdf293cddcb997317e100b9e3dab1db3ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
